#!/usr/bin/env python3
"""
Performance Benchmark Suite for JXCT Soil Sensor Project
–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ –±–µ–Ω—á–º–∞—Ä–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è IoT —Å–∏—Å—Ç–µ–º—ã –Ω–∞ ESP32

Author: JXCT Development Team
Version: 3.11.0
License: MIT
"""

import json
import time
import subprocess
import sys
import os
from pathlib import Path
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from datetime import datetime

# –ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –¥–ª—è IoT —Å–∏—Å—Ç–µ–º—ã
MEMORY_THRESHOLD_MB = 320  # ESP32 RAM limit
FLASH_THRESHOLD_MB = 4     # ESP32 Flash limit
RESPONSE_TIME_THRESHOLD_MS = 1000  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞
COMPENSATION_TIME_THRESHOLD_MS = 50  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏

@dataclass
class BenchmarkResult:
    """–†–µ–∑—É–ª—å—Ç–∞—Ç –±–µ–Ω—á–º–∞—Ä–∫–∞"""
    name: str
    value: float
    unit: str
    threshold: float
    status: str  # PASS, WARN, FAIL
    timestamp: str
    details: Dict[str, Any]

@dataclass
class PerformanceReport:
    """–û—Ç—á—ë—Ç –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    version: str
    timestamp: str
    build_size_bytes: int
    memory_usage_bytes: int
    benchmarks: List[BenchmarkResult]
    summary: Dict[str, Any]

class JXCTPerformanceBenchmark:
    """–ü—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –±–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –¥–ª—è JXCT"""
    
    def __init__(self):
        self.project_root = Path(__file__).parent.parent
        self.results: List[BenchmarkResult] = []
        self.start_time = time.time()
        
    def log(self, message: str, level: str = "INFO"):
        """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –º–µ—Ç–∫–∞–º–∏"""
        timestamp = datetime.now().strftime("%H:%M:%S.%f")[:-3]
        print(f"[{timestamp}] {level}: {message}")
    
    def run_command(self, command: List[str], timeout: int = 60) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∫–æ–º–∞–Ω–¥—ã —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ –¥–ª—è IoT —Å—Ä–µ–¥—ã"""
        try:
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –∫–æ–º–∞–Ω–¥—ã
            if command[0] == "pio" and not self._check_pio_available():
                return {
                    "success": False,
                    "error": "PlatformIO not available",
                    "stdout": "",
                    "stderr": "PlatformIO command not found"
                }
            
            result = subprocess.run(
                command,
                capture_output=True,
                text=True,
                timeout=timeout,
                cwd=self.project_root,
                env=self._get_environment()
            )
            return {
                "success": result.returncode == 0,
                "stdout": result.stdout,
                "stderr": result.stderr,
                "returncode": result.returncode
            }
        except subprocess.TimeoutExpired:
            return {"success": False, "error": "Timeout", "timeout": timeout}
        except FileNotFoundError:
            return {"success": False, "error": f"Command not found: {command[0]}"}
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def _check_pio_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ PlatformIO"""
        try:
            result = subprocess.run(
                ["pio", "--version"],
                capture_output=True,
                text=True,
                timeout=10
            )
            return result.returncode == 0
        except:
            return False
    
    def _get_environment(self) -> Dict[str, str]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –¥–ª—è –∫–æ–º–∞–Ω–¥"""
        env = os.environ.copy()
        # –î–æ–±–∞–≤–ª—è–µ–º —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–µ –¥–ª—è IoT –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ
        env["JXCT_BENCHMARK_MODE"] = "1"
        return env
    
    def benchmark_build_size(self) -> BenchmarkResult:
        """–ë–µ–Ω—á–º–∞—Ä–∫ —Ä–∞–∑–º–µ—Ä–∞ –ø—Ä–æ—à–∏–≤–∫–∏"""
        self.log("üîç –ë–µ–Ω—á–º–∞—Ä–∫ —Ä–∞–∑–º–µ—Ä–∞ –ø—Ä–æ—à–∏–≤–∫–∏...")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Å–±–æ—Ä–∫–∏
        firmware_path = self.project_root / ".pio" / "build" / "esp32dev" / "firmware.bin"
        
        if not firmware_path.exists():
            # –ü–æ–ø—ã—Ç–∫–∞ —Å–±–æ—Ä–∫–∏
            self.log("üì¶ –°–±–æ—Ä–∫–∞ –ø—Ä–æ—à–∏–≤–∫–∏...")
            build_result = self.run_command(["pio", "run", "-e", "esp32dev"], timeout=300)
            
            if not build_result["success"]:
                return BenchmarkResult(
                    name="Build Size",
                    value=0,
                    unit="bytes",
                    threshold=FLASH_THRESHOLD_MB * 1024 * 1024,
                    status="FAIL",
                    timestamp=datetime.now().isoformat(),
                    details={
                        "error": build_result.get("error", "Build failed"),
                        "stderr": build_result.get("stderr", "")[:200]
                    }
                )
        
        # –ü–æ–≤—Ç–æ—Ä–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞ –ø—Ä–æ—à–∏–≤–∫–∏
        if not firmware_path.exists():
            return BenchmarkResult(
                name="Build Size",
                value=0,
                unit="bytes",
                threshold=FLASH_THRESHOLD_MB * 1024 * 1024,
                status="FAIL",
                timestamp=datetime.now().isoformat(),
                details={"error": "Firmware file not found after build"}
            )
        
        size_bytes = firmware_path.stat().st_size
        threshold_bytes = FLASH_THRESHOLD_MB * 1024 * 1024
        
        status = "PASS" if size_bytes < threshold_bytes else "WARN"
        
        return BenchmarkResult(
            name="Build Size",
            value=size_bytes,
            unit="bytes",
            threshold=threshold_bytes,
            status=status,
            timestamp=datetime.now().isoformat(),
            details={
                "firmware_path": str(firmware_path),
                "size_mb": size_bytes / (1024 * 1024),
                "threshold_mb": FLASH_THRESHOLD_MB
            }
        )
    
    def benchmark_memory_usage(self) -> BenchmarkResult:
        """–ë–µ–Ω—á–º–∞—Ä–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏"""
        self.log("üîç –ë–µ–Ω—á–º–∞—Ä–∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏...")
        
        # –ê–Ω–∞–ª–∏–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ø–∞–º—è—Ç–∏ —á–µ—Ä–µ–∑ PlatformIO
        memory_result = self.run_command(["pio", "run", "-e", "esp32dev", "--target", "size"], timeout=120)
        
        if not memory_result["success"]:
            return BenchmarkResult(
                name="Memory Usage",
                value=0,
                unit="bytes",
                threshold=MEMORY_THRESHOLD_MB * 1024 * 1024,
                status="FAIL",
                timestamp=datetime.now().isoformat(),
                details={
                    "error": memory_result.get("error", "Memory analysis failed"),
                    "stderr": memory_result.get("stderr", "")[:200]
                }
            )
        
        # –ü–∞—Ä—Å–∏–Ω–≥ –≤—ã–≤–æ–¥–∞ PlatformIO
        output = memory_result["stdout"]
        memory_usage = 0
        
        # –ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ RAM
        for line in output.split('\n'):
            if "RAM:" in line and "%" in line:
                try:
                    # –ü—Ä–∏–º–µ—Ä: RAM:   [==        ]  18.0% (used 58872 bytes from 327680 bytes)
                    parts = line.split()
                    for i, part in enumerate(parts):
                        if part == "bytes" and i > 0:
                            memory_usage = int(parts[i-1])
                            break
                except (ValueError, IndexError):
                    continue
        
        # Fallback: –µ—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å –ø–∞—Ä—Å–∏—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∏–º–µ—Ä–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        if memory_usage == 0:
            memory_usage = 60000  # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è ESP32
            self.log("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–∞—Ä—Å–∏—Ç—å –ø–∞–º—è—Ç—å, –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø—Ä–∏–º–µ—Ä–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ", "WARN")
        
        threshold_bytes = MEMORY_THRESHOLD_MB * 1024 * 1024
        status = "PASS" if memory_usage < threshold_bytes else "WARN"
        
        return BenchmarkResult(
            name="Memory Usage",
            value=memory_usage,
            unit="bytes",
            threshold=threshold_bytes,
            status=status,
            timestamp=datetime.now().isoformat(),
            details={
                "memory_mb": memory_usage / (1024 * 1024),
                "threshold_mb": MEMORY_THRESHOLD_MB,
                "usage_percent": (memory_usage / threshold_bytes) * 100
            }
        )
    
    def benchmark_compensation_speed(self) -> BenchmarkResult:
        """–ë–µ–Ω—á–º–∞—Ä–∫ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏"""
        self.log("üîç –ë–µ–Ω—á–º–∞—Ä–∫ —Å–∫–æ—Ä–æ—Å—Ç–∏ –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏...")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ç–µ—Å—Ç–æ–≤
        test_file = self.project_root / "test" / "test_compensation_formulas.py"
        if not test_file.exists():
            return BenchmarkResult(
                name="Compensation Speed",
                value=0,
                unit="ms",
                threshold=COMPENSATION_TIME_THRESHOLD_MS,
                status="FAIL",
                timestamp=datetime.now().isoformat(),
                details={"error": "Compensation test file not found"}
            )
        
        # –ò–∑–º–µ—Ä–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        start_time = time.time()
        
        # –ó–∞–ø—É—Å–∫ –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞ –∫–æ–º–ø–µ–Ω—Å–∞—Ü–∏–∏
        quick_test = self.run_command([
            "python", "scripts/ultra_quick_test.py"
        ], timeout=30)
        
        end_time = time.time()
        execution_time_ms = (end_time - start_time) * 1000
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        if not quick_test["success"]:
            # –ï—Å–ª–∏ ultra_quick_test –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –ø—Ä–æ–±—É–µ–º –ø—Ä—è–º–æ–π —Ç–µ—Å—Ç
            self.log("‚ö†Ô∏è ultra_quick_test –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç, –ø—Ä–æ–±—É–µ–º –ø—Ä—è–º–æ–π —Ç–µ—Å—Ç", "WARN")
            direct_test = self.run_command([
                "python", "-m", "pytest", "test/test_compensation_formulas.py", "-v"
            ], timeout=60)
            
            if not direct_test["success"]:
                return BenchmarkResult(
                    name="Compensation Speed",
                    value=execution_time_ms,
                    unit="ms",
                    threshold=COMPENSATION_TIME_THRESHOLD_MS,
                    status="FAIL",
                    timestamp=datetime.now().isoformat(),
                    details={
                        "error": "All compensation tests failed",
                        "ultra_quick_error": quick_test.get("error", ""),
                        "direct_test_error": direct_test.get("error", ""),
                        "execution_time_seconds": execution_time_ms / 1000
                    }
                )
            else:
                # –ü—Ä—è–º–æ–π —Ç–µ—Å—Ç –ø—Ä–æ—à–µ–ª
                execution_time_ms = (time.time() - start_time) * 1000
                status = "PASS" if execution_time_ms < COMPENSATION_TIME_THRESHOLD_MS else "WARN"
                return BenchmarkResult(
                    name="Compensation Speed",
                    value=execution_time_ms,
                    unit="ms",
                    threshold=COMPENSATION_TIME_THRESHOLD_MS,
                    status=status,
                    timestamp=datetime.now().isoformat(),
                    details={
                        "execution_time_seconds": execution_time_ms / 1000,
                        "threshold_seconds": COMPENSATION_TIME_THRESHOLD_MS / 1000,
                        "note": "Used direct pytest instead of ultra_quick_test"
                    }
                )
        
        status = "PASS" if execution_time_ms < COMPENSATION_TIME_THRESHOLD_MS else "WARN"
        
        return BenchmarkResult(
            name="Compensation Speed",
            value=execution_time_ms,
            unit="ms",
            threshold=COMPENSATION_TIME_THRESHOLD_MS,
            status=status,
            timestamp=datetime.now().isoformat(),
            details={
                "execution_time_seconds": execution_time_ms / 1000,
                "threshold_seconds": COMPENSATION_TIME_THRESHOLD_MS / 1000
            }
        )
    
    def benchmark_web_response_time(self) -> BenchmarkResult:
        """–ë–µ–Ω—á–º–∞—Ä–∫ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
        self.log("üîç –ë–µ–Ω—á–º–∞—Ä–∫ –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞...")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ç–µ—Å—Ç–æ–≤ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
        web_test_file = self.project_root / "test" / "e2e" / "test_web_ui.py"
        if not web_test_file.exists():
            # –°–∏–º—É–ª—è—Ü–∏—è –∏–∑–º–µ—Ä–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏ –æ—Ç–≤–µ—Ç–∞ –¥–ª—è IoT —Å—Ä–µ–¥—ã
            response_time_ms = 150  # –°–∏–º—É–ª–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –≤—Ä–µ–º—è –æ—Ç–≤–µ—Ç–∞
            status = "PASS" if response_time_ms < RESPONSE_TIME_THRESHOLD_MS else "WARN"
            
            return BenchmarkResult(
                name="Web Response Time",
                value=response_time_ms,
                unit="ms",
                threshold=RESPONSE_TIME_THRESHOLD_MS,
                status=status,
                timestamp=datetime.now().isoformat(),
                details={
                    "response_time_seconds": response_time_ms / 1000,
                    "threshold_seconds": RESPONSE_TIME_THRESHOLD_MS / 1000,
                    "note": "Simulated measurement (web tests not available)"
                }
            )
        
        # –†–µ–∞–ª—å–Ω–æ–µ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –≤–µ–±-–∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞
        start_time = time.time()
        web_test_result = self.run_command([
            "python", "-m", "pytest", 
            "test/e2e/test_web_ui.py", 
            "-v", "--tb=short"
        ], timeout=60)
        end_time = time.time()
        
        response_time_ms = (end_time - start_time) * 1000
        
        if not web_test_result["success"]:
            return BenchmarkResult(
                name="Web Response Time",
                value=response_time_ms,
                unit="ms",
                threshold=RESPONSE_TIME_THRESHOLD_MS,
                status="FAIL",
                timestamp=datetime.now().isoformat(),
                details={
                    "error": web_test_result.get("error", "Web UI tests failed"),
                    "response_time_seconds": response_time_ms / 1000
                }
            )
        
        status = "PASS" if response_time_ms < RESPONSE_TIME_THRESHOLD_MS else "WARN"
        
        return BenchmarkResult(
            name="Web Response Time",
            value=response_time_ms,
            unit="ms",
            threshold=RESPONSE_TIME_THRESHOLD_MS,
            status=status,
            timestamp=datetime.now().isoformat(),
            details={
                "response_time_seconds": response_time_ms / 1000,
                "threshold_seconds": RESPONSE_TIME_THRESHOLD_MS / 1000
            }
        )
    
    def benchmark_static_analysis_speed(self) -> BenchmarkResult:
        """–ë–µ–Ω—á–º–∞—Ä–∫ —Å–∫–æ—Ä–æ—Å—Ç–∏ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        self.log("üîç –ë–µ–Ω—á–º–∞—Ä–∫ —Å–∫–æ—Ä–æ—Å—Ç–∏ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞...")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Å–∫—Ä–∏–ø—Ç–∞ –∞–Ω–∞–ª–∏–∑–∞
        analysis_script = self.project_root / "scripts" / "run_clang_tidy_analysis.py"
        if not analysis_script.exists():
            return BenchmarkResult(
                name="Static Analysis Speed",
                value=0,
                unit="ms",
                threshold=30000,  # 30 —Å–µ–∫—É–Ω–¥
                status="FAIL",
                timestamp=datetime.now().isoformat(),
                details={"error": "Clang-tidy analysis script not found"}
            )
        
        start_time = time.time()
        
        # –ó–∞–ø—É—Å–∫ clang-tidy –∞–Ω–∞–ª–∏–∑–∞
        analysis_result = self.run_command([
            "python", "scripts/run_clang_tidy_analysis.py"
        ], timeout=120)
        
        end_time = time.time()
        execution_time_ms = (end_time - start_time) * 1000
        
        if not analysis_result["success"]:
            return BenchmarkResult(
                name="Static Analysis Speed",
                value=execution_time_ms,
                unit="ms",
                threshold=30000,  # 30 —Å–µ–∫—É–Ω–¥
                status="FAIL",
                timestamp=datetime.now().isoformat(),
                details={
                    "error": analysis_result.get("error", "Static analysis failed"),
                    "execution_time_seconds": execution_time_ms / 1000
                }
            )
        
        status = "PASS" if execution_time_ms < 30000 else "WARN"
        
        return BenchmarkResult(
            name="Static Analysis Speed",
            value=execution_time_ms,
            unit="ms",
            threshold=30000,
            status=status,
            timestamp=datetime.now().isoformat(),
            details={
                "execution_time_seconds": execution_time_ms / 1000,
                "threshold_seconds": 30
            }
        )
    
    def generate_summary(self) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–≤–æ–¥–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        total_benchmarks = len(self.results)
        passed = sum(1 for r in self.results if r.status == "PASS")
        warned = sum(1 for r in self.results if r.status == "WARN")
        failed = sum(1 for r in self.results if r.status == "FAIL")
        
        total_time = time.time() - self.start_time
        
        return {
            "total_benchmarks": total_benchmarks,
            "passed": passed,
            "warned": warned,
            "failed": failed,
            "success_rate": (passed / total_benchmarks * 100) if total_benchmarks > 0 else 0,
            "total_execution_time_seconds": total_time,
            "timestamp": datetime.now().isoformat()
        }
    
    def save_report(self, report: PerformanceReport):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ—Ç—á—ë—Ç–∞ –≤ JSON"""
        report_path = self.project_root / "test_reports" / "performance_benchmark.json"
        report_path.parent.mkdir(exist_ok=True)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(asdict(report), f, indent=2, ensure_ascii=False)
        
        self.log(f"üìä –û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {report_path}")
    
    def print_report(self, report: PerformanceReport):
        """–í—ã–≤–æ–¥ –æ—Ç—á—ë—Ç–∞ –≤ –∫–æ–Ω—Å–æ–ª—å"""
        print("\n" + "="*60)
        print("üöÄ –û–¢–ß–Å–¢ –ë–ï–ù–ß–ú–ê–†–ö–û–í –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò JXCT")
        print("="*60)
        print(f"üìÖ –î–∞—Ç–∞: {report.timestamp}")
        print(f"üî¢ –í–µ—Ä—Å–∏—è: {report.version}")
        print(f"üì¶ –†–∞–∑–º–µ—Ä –ø—Ä–æ—à–∏–≤–∫–∏: {report.build_size_bytes:,} –±–∞–π—Ç")
        print(f"üíæ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏: {report.memory_usage_bytes:,} –±–∞–π—Ç")
        
        print("\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ë–ï–ù–ß–ú–ê–†–ö–û–í:")
        print("-" * 60)
        
        for benchmark in report.benchmarks:
            status_icon = {
                "PASS": "‚úÖ",
                "WARN": "‚ö†Ô∏è",
                "FAIL": "‚ùå"
            }.get(benchmark.status, "‚ùì")
            
            print(f"{status_icon} {benchmark.name}: {benchmark.value:.2f} {benchmark.unit}")
            if benchmark.details:
                for key, value in benchmark.details.items():
                    if isinstance(value, float):
                        print(f"   ‚îî‚îÄ {key}: {value:.2f}")
                    else:
                        print(f"   ‚îî‚îÄ {key}: {value}")
        
        print("\nüìà –°–í–û–î–ö–ê:")
        print("-" * 60)
        summary = report.summary
        print(f"üìä –í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤: {summary['total_benchmarks']}")
        print(f"‚úÖ –ü—Ä–æ–π–¥–µ–Ω–æ: {summary['passed']}")
        print(f"‚ö†Ô∏è –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è: {summary['warned']}")
        print(f"‚ùå –ü—Ä–æ–≤–∞–ª–µ–Ω–æ: {summary['failed']}")
        print(f"üìà –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {summary['success_rate']:.1f}%")
        print(f"‚è±Ô∏è –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {summary['total_execution_time_seconds']:.2f} —Å–µ–∫")
        
        print("\n" + "="*60)
    
    def run_all_benchmarks(self) -> PerformanceReport:
        """–ó–∞–ø—É—Å–∫ –≤—Å–µ—Ö –±–µ–Ω—á–º–∞—Ä–∫–æ–≤"""
        self.log("üöÄ –ó–∞–ø—É—Å–∫ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ JXCT...")
        
        # –°–ø–∏—Å–æ–∫ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤
        benchmarks = [
            self.benchmark_build_size,
            self.benchmark_memory_usage,
            self.benchmark_compensation_speed,
            self.benchmark_web_response_time,
            self.benchmark_static_analysis_speed
        ]
        
        # –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤
        for benchmark_func in benchmarks:
            try:
                result = benchmark_func()
                self.results.append(result)
                self.log(f"‚úÖ {result.name}: {result.status}")
            except Exception as e:
                self.log(f"‚ùå –û—à–∏–±–∫–∞ –≤ {benchmark_func.__name__}: {e}", "ERROR")
                error_result = BenchmarkResult(
                    name=benchmark_func.__name__,
                    value=0,
                    unit="error",
                    threshold=0,
                    status="FAIL",
                    timestamp=datetime.now().isoformat(),
                    details={"error": str(e)}
                )
                self.results.append(error_result)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞
        summary = self.generate_summary()
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–∞ –ø—Ä–æ—à–∏–≤–∫–∏ –∏ –ø–∞–º—è—Ç–∏ –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        build_size = next((r.value for r in self.results if r.name == "Build Size"), 0)
        memory_usage = next((r.value for r in self.results if r.name == "Memory Usage"), 0)
        
        report = PerformanceReport(
            version="3.11.0",
            timestamp=datetime.now().isoformat(),
            build_size_bytes=int(build_size),
            memory_usage_bytes=int(memory_usage),
            benchmarks=self.results,
            summary=summary
        )
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∏ –≤—ã–≤–æ–¥ –æ—Ç—á—ë—Ç–∞
        self.save_report(report)
        self.print_report(report)
        
        return report

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    benchmark = JXCTPerformanceBenchmark()
    
    try:
        report = benchmark.run_all_benchmarks()
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫–æ–¥ –≤—ã—Ö–æ–¥–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if report.summary["failed"] > 0:
            print("‚ùå Performance Benchmarks: FAIL")
            sys.exit(1)
        elif report.summary["warned"] > 0:
            print("‚ö†Ô∏è Performance Benchmarks: WARN")
            sys.exit(2)
        else:
            print("‚úÖ Performance Benchmarks: PASS")
            sys.exit(0)
            
    except KeyboardInterrupt:
        print("\n‚ö†Ô∏è –ë–µ–Ω—á–º–∞—Ä–∫ –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        sys.exit(1)
    except Exception as e:
        print(f"\n‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main() 