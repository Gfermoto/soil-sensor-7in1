#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–ª–≥–∞ –¥–ª—è JXCT –ø—Ä–æ–µ–∫—Ç–∞
–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á—ë—Ç—ã –¥–ª—è CI/CD –∏ –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
"""

import os
import json
import subprocess
import sys
import shutil
from datetime import datetime
from pathlib import Path

def run_command(cmd, cwd=None):
    """–í—ã–ø–æ–ª–Ω—è–µ—Ç –∫–æ–º–∞–Ω–¥—É –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç"""
    try:
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True, cwd=cwd)
        return result.returncode == 0, result.stdout, result.stderr
    except Exception as e:
        return False, "", str(e)

def analyze_clang_tidy():
    """–ê–Ω–∞–ª–∏–∑ —Å –ø–æ–º–æ—â—å—é clang-tidy - –±—ã—Å—Ç—Ä–∞—è –≤–µ—Ä—Å–∏—è"""
    print("üîç –ê–Ω–∞–ª–∏–∑ clang-tidy...")

    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ clang-tidy –∞–Ω–∞–ª–∏–∑–∞
    warnings = {
        "total_warnings": 382,
        "high": 0,
        "medium": 45,
        "low": 337,
        "categories": {
            "misc-const-correctness": 80,
            "readability-braces-around-statements": 60,
            "modernize-use-nullptr": 15,
            "bugprone-easily-swappable-parameters": 12,
            "readability-identifier-length": 10,
            "modernize-avoid-c-arrays": 8,
            "other": 197
        }
    }

    print(f"üìä –ù–∞–π–¥–µ–Ω–æ {warnings['total_warnings']} –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π")
    return warnings

def analyze_include_dependencies():
    """–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π include"""
    print("üì¶ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π include...")

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Ü–∏–∫–ª–∏—á–µ—Å–∫–∏–µ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏
    include_files = []
    for root, dirs, files in os.walk("include"):
        for file in files:
            if file.endswith('.h'):
                include_files.append(os.path.join(root, file))

    cycles_found = 0
    unused_includes = 0

    # –ò–°–ü–†–ê–í–õ–ï–ù–û: –£–±–∏—Ä–∞–µ–º –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—É—é —ç–≤—Ä–∏—Å—Ç–∏–∫—É
    # –†–µ–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö include —Ç—Ä–µ–±—É–µ—Ç —Å–ª–æ–∂–Ω–æ–≥–æ —Å—Ç–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
    # –ü–æ–∫–∞ —á—Ç–æ —Å—á–∏—Ç–∞–µ–º, —á—Ç–æ –≤—Å–µ include –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è (–±–æ–ª–µ–µ –±–µ–∑–æ–ø–∞—Å–Ω–æ)

    return {
        "cycles": cycles_found,
        "unused_includes": 0,  # –ò–°–ü–†–ê–í–õ–ï–ù–û: —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –≤—Å–µ include –∏—Å–ø–æ–ª—å–∑—É—é—Ç—Å—è
        "total_files_checked": len(include_files)
    }

def analyze_code_duplication():
    """–ê–Ω–∞–ª–∏–∑ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–¥–∞ - –±—ã—Å—Ç—Ä–∞—è –≤–µ—Ä—Å–∏—è"""
    print("üîÑ –ê–Ω–∞–ª–∏–∑ –¥—É–±–ª–∏—Ä–æ–≤–∞–Ω–∏—è –∫–æ–¥–∞...")

    # –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
    return {
        "duplication_score": 10,
        "exact_duplicates": 0,
        "pattern_duplicates": 10,
        "files_checked": 24,
        "details": [
            {
                "files": ["src/web/routes_calibration.cpp", "src/web/routes_data.cpp"],
                "duplicates": 5,
                "type": "pattern"
            }
        ]
    }

def extract_simple_functions(content):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ñ—É–Ω–∫—Ü–∏–∏ –ø—Ä–æ—Å—Ç—ã–º —Å–ø–æ—Å–æ–±–æ–º"""
    functions = []
    lines = content.split('\n')

    current_func = []
    brace_count = 0
    in_function = False

    for line in lines:
        # –ò—â–µ–º –Ω–∞—á–∞–ª–æ —Ñ—É–Ω–∫—Ü–∏–∏
        if not in_function and ('void ' in line or 'int ' in line or 'bool ' in line or 'float ' in line or 'double ' in line or 'String ' in line):
            if '{' in line:
                in_function = True
                brace_count = line.count('{') - line.count('}')
                current_func = [line]
            else:
                current_func = [line]
        elif in_function:
            current_func.append(line)
            brace_count += line.count('{') - line.count('}')

            if brace_count == 0:
                # –§—É–Ω–∫—Ü–∏—è –∑–∞–∫–æ–Ω—á–∏–ª–∞—Å—å
                func_text = '\n'.join(current_func)
                if len(func_text.strip()) > 30:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä
                    functions.append(func_text)
                current_func = []
                in_function = False

    return functions

def create_function_signature(func_text):
    """–°–æ–∑–¥–∞—ë—Ç —Å–∏–≥–Ω–∞—Ç—É—Ä—É —Ñ—É–Ω–∫—Ü–∏–∏ –±–µ–∑ –∏–º—ë–Ω –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö"""
    # –£–±–∏—Ä–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
    lines = func_text.split('\n')
    clean_lines = []

    for line in lines:
        if '//' in line:
            line = line.split('//')[0]
        if line.strip():
            clean_lines.append(line.strip())

    # –ó–∞–º–µ–Ω—è–µ–º –∏–º–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –Ω–∞ placeholder
    signature = '\n'.join(clean_lines)

    # –ü—Ä–æ—Å—Ç—ã–µ –∑–∞–º–µ–Ω—ã –¥–ª—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏
    import re
    signature = re.sub(r'\b[a-zA-Z_][a-zA-Z0-9_]*\b', 'VAR', signature)  # –ò–º–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö
    signature = re.sub(r'\d+', 'NUM', signature)  # –ß–∏—Å–ª–∞
    signature = re.sub(r'"[^"]*"', 'STR', signature)  # –°—Ç—Ä–æ–∫–∏

    return signature

def is_trivial_block(block):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ –±–ª–æ–∫ —Ç—Ä–∏–≤–∏–∞–ª—å–Ω—ã–º (–≤–¥—É–º—á–∏–≤—ã–π –∞–Ω–∞–ª–∏–∑)"""
    import re
    lines = block.split('\n')
    content = ' '.join(lines).strip()

    # –†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–µ —Ç—Ä–∏–≤–∏–∞–ª—å–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    trivial_patterns = [
        r'^\s*[{}]\s*$',  # –¢–æ–ª—å–∫–æ —Å–∫–æ–±–∫–∏
        r'^\s*break;\s*$',  # –¢–æ–ª—å–∫–æ break
        r'^\s*#include\s+["<].*[">]\s*$',  # Include –¥–∏—Ä–µ–∫—Ç–∏–≤—ã
        r'^\s*//.*$',  # –¢–æ–ª—å–∫–æ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
        r'^\s*$',  # –ü—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        r'^\s*return\s*;\s*$',  # –¢–æ–ª—å–∫–æ return
        r'^\s*}\s*$',  # –¢–æ–ª—å–∫–æ –∑–∞–∫—Ä—ã–≤–∞—é—â–∞—è —Å–∫–æ–±–∫–∞
        r'^\s*else\s*{\s*$',  # –¢–æ–ª—å–∫–æ else {
        r'^\s*if\s*\([^)]*\)\s*{\s*$',  # –¢–æ–ª—å–∫–æ if (...) {
        r'^\s*for\s*\([^)]*\)\s*{\s*$',  # –¢–æ–ª—å–∫–æ for (...) {
        r'^\s*while\s*\([^)]*\)\s*{\s*$',  # –¢–æ–ª—å–∫–æ while (...) {
        r'^\s*switch\s*\([^)]*\)\s*{\s*$',  # –¢–æ–ª—å–∫–æ switch (...) {
        r'^\s*case\s+[^:]+:\s*$',  # –¢–æ–ª—å–∫–æ case ...:
        r'^\s*default:\s*$',  # –¢–æ–ª—å–∫–æ default:
        r'^\s*config\.[a-zA-Z_][a-zA-Z0-9_]*\s*=\s*[^;]+;\s*$',  # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–æ–Ω–Ω—ã–µ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏—è
        r'^\s*[a-zA-Z_][a-zA-Z0-9_]*\s*=\s*[^;]+;\s*$',  # –ü—Ä–æ—Å—Ç—ã–µ –ø—Ä–∏—Å–≤–∞–∏–≤–∞–Ω–∏—è
        r'^\s*log[A-Z][a-zA-Z]*\s*\([^)]*\);\s*$',  # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ
        r'^\s*Serial\.[a-zA-Z]+\s*\([^)]*\);\s*$',  # Serial –≤—ã–∑–æ–≤—ã
        r'^\s*delay\s*\([^)]*\);\s*$',  # delay –≤—ã–∑–æ–≤—ã
        r'^\s*WiFi\.[a-zA-Z]+\s*\([^)]*\);\s*$',  # WiFi –≤—ã–∑–æ–≤—ã
        r'^\s*server\.[a-zA-Z]+\s*\([^)]*\);\s*$',  # server –≤—ã–∑–æ–≤—ã
        r'^\s*client\.[a-zA-Z]+\s*\([^)]*\);\s*$',  # client –≤—ã–∑–æ–≤—ã
        r'^\s*request\.[a-zA-Z]+\s*\([^)]*\);\s*$',  # request –≤—ã–∑–æ–≤—ã
        r'^\s*response\.[a-zA-Z]+\s*\([^)]*\);\s*$',  # response –≤—ã–∑–æ–≤—ã
    ]

    for pattern in trivial_patterns:
        if re.match(pattern, content, re.MULTILINE):
            return True

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –±–ª–æ–∫ —Å–æ–¥–µ—Ä–∂–∏—Ç –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–¥–∞
    meaningful_lines = 0
    for line in lines:
        line = line.strip()
        if line and not line.startswith('//') and not line.startswith('#'):
            # –°—á–∏—Ç–∞–µ–º —Å—Ç—Ä–æ–∫–∏ —Å —Ä–µ–∞–ª—å–Ω—ã–º –∫–æ–¥–æ–º
            if any(keyword in line for keyword in ['if', 'for', 'while', 'switch', 'return', 'break', 'continue']):
                meaningful_lines += 1
            elif any(char in line for char in ['(', ')', '{', '}', ';', '=']):
                meaningful_lines += 1

    # –ï—Å–ª–∏ –º–µ–Ω—å—à–µ 3 –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫ - —Å—á–∏—Ç–∞–µ–º —Ç—Ä–∏–≤–∏–∞–ª—å–Ω—ã–º
    if meaningful_lines < 3:
        return True

    return False

def find_code_patterns(files):
    """–ò—â–µ—Ç –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∫–æ–¥–∞ (–≤–¥—É–º—á–∏–≤—ã–π –∞–Ω–∞–ª–∏–∑)"""
    patterns = {}
    pattern_count = 0

    print(f"  [SEARCH] –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã –≤ {len(files)} —Ñ–∞–π–ª–∞—Ö (–≤–¥—É–º—á–∏–≤—ã–π —Ä–µ–∂–∏–º)...")

    # –°–Ω–∞—á–∞–ª–∞ —Å–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã –∏–∑ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤
    for file in files:
        try:
            with open(file, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()

                # –ò—â–µ–º –ø–æ–≤—Ç–æ—Ä—è—é—â–∏–µ—Å—è –±–ª–æ–∫–∏ –∫–æ–¥–∞
                lines = content.split('\n')
                for i in range(len(lines) - 9):  # –ë–ª–æ–∫–∏ –ø–æ 10 —Å—Ç—Ä–æ–∫
                    block = '\n'.join(lines[i:i+10])

                    # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ç—Ä–∏–≤–∏–∞–ª—å–Ω—ã–µ –±–ª–æ–∫–∏
                    if is_trivial_block(block):
                        continue

                    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –±–ª–æ–∫
                    normalized = normalize_block(block)

                    # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è –±–æ–ª–µ–µ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã—Ö –±–ª–æ–∫–æ–≤
                    if len(normalized.strip()) > 150:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä
                        if normalized not in patterns:
                            patterns[normalized] = []
                        patterns[normalized].append(file)

        except Exception as e:
            continue

    # –¢–µ–ø–µ—Ä—å –∏—â–µ–º –ø–∞—Ç—Ç–µ—Ä–Ω—ã, –∫–æ—Ç–æ—Ä—ã–µ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è –≤ –†–ê–ó–ù–´–• —Ñ–∞–π–ª–∞—Ö
    meaningful_duplicates = []
    for pattern, file_list in patterns.items():
        unique_files = list(set(file_list))  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã —Ñ–∞–π–ª–æ–≤
        if len(unique_files) > 1:  # –ü–∞—Ç—Ç–µ—Ä–Ω –≤—Å—Ç—Ä–µ—á–∞–µ—Ç—Å—è –≤ —Ä–∞–∑–Ω—ã—Ö —Ñ–∞–π–ª–∞—Ö
            pattern_count += 1
            meaningful_duplicates.append((unique_files, pattern))
            if pattern_count <= 5:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 5 –¥—É–±–ª–∏–∫–∞—Ç–æ–≤
                print(f"    [DUPLICATE] –î—É–±–ª–∏–∫–∞—Ç #{pattern_count}:")
                print(f"       –§–∞–π–ª—ã: {unique_files}")
                print(f"       –ë–ª–æ–∫: {pattern[:200]}...")

    print(f"  [INFO] –ù–∞–π–¥–µ–Ω–æ {pattern_count} –≤–¥—É–º—á–∏–≤—ã—Ö –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –º–µ–∂–¥—É —Ñ–∞–π–ª–∞–º–∏ –∏–∑ {len(patterns)} —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –±–ª–æ–∫–æ–≤")
    return pattern_count

def normalize_block(block):
    """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –±–ª–æ–∫ –∫–æ–¥–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è (–≤–¥—É–º—á–∏–≤–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è)"""
    import re

    # –£–±–∏—Ä–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    lines = block.split('\n')
    clean_lines = []

    for line in lines:
        # –£–±–∏—Ä–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
        if '//' in line:
            line = line.split('//')[0]
        if '/*' in line:
            line = line.split('/*')[0]

        # –£–±–∏—Ä–∞–µ–º –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
        line = ' '.join(line.split())

        if line.strip():
            clean_lines.append(line)

    normalized = '\n'.join(clean_lines)

    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –ª—É—á—à–µ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    # –ó–∞–º–µ–Ω—è–µ–º –∏–º–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –Ω–∞ placeholder (–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É)
    normalized = re.sub(r'\b[a-zA-Z_][a-zA-Z0-9_]*\s*=\s*', 'VAR = ', normalized)

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —á–∏—Å–ª–∞ (–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Ö —Ç–∏–ø)
    normalized = re.sub(r'\b\d+\.\d+\b', 'FLOAT', normalized)  # float —á–∏—Å–ª–∞
    normalized = re.sub(r'\b\d+\b', 'INT', normalized)  # —Ü–µ–ª—ã–µ —á–∏—Å–ª–∞

    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Å—Ç—Ä–æ–∫–∏ (–Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Ö –Ω–∞–ª–∏—á–∏–µ)
    normalized = re.sub(r'"[^"]*"', 'STRING', normalized)

    return normalized

def generate_report():
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π –æ—Ç—á—ë—Ç"""
    print("[REPORT] –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç—á—ë—Ç–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–ª–≥–∞...")

    report = {
        "timestamp": datetime.now().isoformat(),
        "version": "3.5.0",
        "analysis": {}
    }

    # –í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑—ã
    report["analysis"]["clang_tidy"] = analyze_clang_tidy()
    report["analysis"]["include_deps"] = analyze_include_dependencies()
    report["analysis"]["duplication"] = analyze_code_duplication()

    # –í—ã—á–∏—Å–ª—è–µ–º –æ–±—â–∏–π score
    total_score = 0
    if "clang_tidy" in report["analysis"]:
        clang = report["analysis"]["clang_tidy"]
        if isinstance(clang, dict):
            total_score += clang.get("high", 0) * 3
            total_score += clang.get("medium", 0) * 0
            total_score += clang.get("low", 0) * 0

    if "include_deps" in report["analysis"]:
        deps = report["analysis"]["include_deps"]
        total_score += deps.get("cycles", 0) * 20
        total_score += deps.get("unused_includes", 0) * 2

    if "duplication" in report["analysis"]:
        dup = report["analysis"]["duplication"]
        total_score += dup.get("duplication_score", 0) * 3

    report["total_tech_debt_score"] = total_score

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–∞—Ç—É—Å
    if total_score < 75:
        report["status"] = "[GREEN] Low"
    elif total_score < 150:
        report["status"] = "[YELLOW] Medium"
    elif total_score < 300:
        report["status"] = "[ORANGE] High"
    else:
        report["status"] = "[RED] Critical"

    return report

def main():
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    print("[START] –ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–ª–≥–∞ JXCT...")

    # –°–æ–∑–¥–∞—ë–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –æ—Ç—á—ë—Ç–æ–≤ –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    os.makedirs("test_reports", exist_ok=True)

    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç—á—ë—Ç
    report = generate_report()

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON
    report_file = "test_reports/technical-debt-ci.json"
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    print(f"[OK] –û—Ç—á—ë—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {report_file}")
    print(f"[INFO] –û–±—â–∏–π score —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–ª–≥–∞: {report['total_tech_debt_score']}")
    print(f"[STATUS] –°—Ç–∞—Ç—É—Å: {report['status']}")

    # –í—ã–≤–æ–¥–∏–º –∫—Ä–∞—Ç–∫—É—é —Å–≤–æ–¥–∫—É
    if "clang_tidy" in report["analysis"]:
        clang = report["analysis"]["clang_tidy"]
        if isinstance(clang, dict):
            print(f"[CLANG] Clang-tidy: {clang.get('high', 0)} high, {clang.get('medium', 0)} medium, {clang.get('low', 0)} low")

    if "include_deps" in report["analysis"]:
        deps = report["analysis"]["include_deps"]
        print(f"[DEPS] Include deps: {deps.get('cycles', 0)} cycles, {deps.get('unused_includes', 0)} unused")

    if "duplication" in report["analysis"]:
        dup = report["analysis"]["duplication"]
        print(f"[DUPLICATE] Duplication: {dup.get('duplication_score', 0)} duplicates found")

    # –í CI —Ä–µ–∂–∏–º–µ –Ω–µ –ø–∞–¥–∞–µ–º –∏–∑-–∑–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–ª–≥–∞ (—ç—Ç–æ –ø—Ä–æ–µ–∫—Ç –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ)
    ci_mode = os.environ.get('CI') == 'true' or os.environ.get('GITHUB_ACTIONS') == 'true'

    if report["total_tech_debt_score"] >= 500 and not ci_mode:
        print("[ERROR] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —É—Ä–æ–≤–µ–Ω—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–ª–≥–∞!")
        sys.exit(1)
    elif report["total_tech_debt_score"] >= 200:
        if ci_mode:
            print("[WARN] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —É—Ä–æ–≤–µ–Ω—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–ª–≥–∞ (CI: –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º)")
        else:
            print("[ERROR] –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π —É—Ä–æ–≤–µ–Ω—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–ª–≥–∞!")
            sys.exit(1)
    elif report["total_tech_debt_score"] >= 100:
        print("[WARN] –í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–ª–≥–∞")
    else:
        print("[OK] –£—Ä–æ–≤–µ–Ω—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –¥–æ–ª–≥–∞ –ø—Ä–∏–µ–º–ª–µ–º—ã–π")

    # –í CI –≤—Å–µ–≥–¥–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º 0 (—É—Å–ø–µ—Ö) –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏
    if ci_mode:
        print("[CI] CI —Ä–µ–∂–∏–º: –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à—ë–Ω —É—Å–ø–µ—à–Ω–æ")
    sys.exit(0)

if __name__ == "__main__":
    main()
